{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. add the zeros (n-1)\n",
    "2. take top n\n",
    "2b. then add in a random number col, then order by id then random number, then drop random number (ergo they are shuffled)\n",
    "3. then values\n",
    "4. then split into number of ids (works because they're the same size)\n",
    "5. then reshape to #dfs (ids), #of dims https://stackoverflow.com/questions/9057379/correct-and-efficient-way-to-flatten-array\n",
    "\n",
    "6. add support for columns that are used for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, let's create our dummy data, nto terribly efficient, but not a disaster either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ids 55109\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['id','1','2','3','4','5','6','7','8','10'])\n",
    "my_randoms = []\n",
    "for i in range(2,10):\n",
    "    my_randoms+=[random.randrange(1,100000,1) for _ in range (10000)] \n",
    "df['id'] = my_randoms\n",
    "for i in range(1,11):\n",
    "    df[str(i)] = i\n",
    "    \n",
    "print(\"Number of unique ids\", len(df['id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, 55,000 odd records, close enough to the 200k ids (and 2m contacts) that the business problem had"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back in the day I did this with a loop over the DataFrame, most definitely unvectorised...  Still it worked, and on some decent hardware it was ahem, tolerable.  Only ever menat to be a PoC it was a good example of bad code migrating to (sort-of) production).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_df(df,pad_value,pad_length,id_col):\n",
    "    id_list = [[id_]*pad_length for id_ in df[id_col].unique()]\n",
    "    id_list = [y for x in id_list for y in x]\n",
    "    df_tmp = pd.DataFrame(columns = df.columns)\n",
    "    df_tmp[id_col] = id_list\n",
    "    df_tmp = df_tmp.fillna(pad_value)\n",
    "    df = df.append(df_tmp)\n",
    "    df = shuffle(df)\n",
    "    df = df.sort_values(by=id_col)\n",
    "    df = df.groupby('id').head(pad_length)\n",
    "    return df\n",
    "\n",
    "def df_padded_to_X(df,id_col):\n",
    "    id_count = df[id_col].unique()\n",
    "    X_tmp1 = np.array(df_padded.drop('id',axis=1).values)\n",
    "    X_tmp2 = np.ravel(X_tmp1)\n",
    "    X = np.array(np.array_split(X_tmp1,id_count))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already things feel better, with RADICALLY reduced line count and a total absence of looping over lists (unless you count the list comprehensions, which are likely to be the new chokepoints). Let's time things!\n",
    "\n",
    "First up, the creation of the padded dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.39 s ± 47.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df_padded = pad_df(df,0,10,'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 and a bit seconds is quite frankly blisteringly quick compared to the hours that the old code took to run.  I'll consider this a win, but what about the data into an X format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 ms ± 49.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit X = df_padded_to_X(df_padded,'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what do you know?  Trivial time with the heavy use of numpy's optimised code a clear winner (mental notes on the data frame manipualtions above...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what have we learnt?  Well, first up we've learnt that being Pythonic really pays off, this code is both shorter in lines, clearner to read (probably) and several orders of magnitude faster.  I'll consider this a win, and wish I'd the headspace to do this back in the day.  Still, one less simian on the back...\n",
    "\n",
    "Next up:\n",
    "\n",
    "- add in unit tests\n",
    "- include one hot encoding coverage\n",
    "- docstrings for the functions\n",
    "- build into a usable pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in time it\n",
    "# add in unit tests\n",
    "# add in functionality to include single id values (e.g. disocunt contact)\n",
    "# add docsstrings etc."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
